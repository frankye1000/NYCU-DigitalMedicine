{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a4a4439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import string\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, corpus\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5fdd26",
   "metadata": {},
   "source": [
    "# 讀資料貼標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83b963a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test / validation data\n",
    "target = \"Train_Textual\"\n",
    "# target = \"Test_Intuitive\"\n",
    "\n",
    "# 訓練資料檔案名稱\n",
    "listdirs = os.listdir(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28262b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(text,y), (text,y), .....]\n",
    "data = []\n",
    "for d in listdirs:\n",
    "    y = d.split(\"_\")[0]\n",
    "    with open(\"{}/{}\".format(target,d), \"r\") as f:\n",
    "        text = f.read()\n",
    "    data.append((text.lower(), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbf9249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6890a3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移除標點符號&數字\n",
    "def remove_punctuation(line):\n",
    "    rule = re.compile(r\"[^a-zA-Z]\")\n",
    "    line = rule.sub(' ',line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc314981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 獲取單詞的詞性\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19b436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edfbd24a",
   "metadata": {},
   "source": [
    "# 資料清整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99a8b638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "temp1 = []\n",
    "for d in data:\n",
    "    text = d[0]\n",
    "    y = d[1]\n",
    "    y = 1 if y == \"Y\" else 0    #\"Y\"=1 其他=0\n",
    "    \n",
    "    # 移除標點符號\n",
    "    text = remove_punctuation(text)\n",
    "\n",
    "    # 斷字\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    \n",
    "    # 詞性\n",
    "    words_tags = pos_tag(words)     # 獲取單詞詞性\n",
    "    \n",
    "    \n",
    "    # 去除停用字 且 字長度>2\n",
    "    nltk_stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    wnl = WordNetLemmatizer()\n",
    "    clean_words = []\n",
    "    for word_tag in words_tags:\n",
    "        wordnet_pos = get_wordnet_pos(word_tag[1]) or wordnet.NOUN\n",
    "        origin_word = wnl.lemmatize(word_tag[0], pos=wordnet_pos)    # 詞性還原\n",
    "#         print(word_tag[0], origin_word)\n",
    "        \n",
    "        if origin_word not in nltk_stopwords and len(origin_word) > 2:\n",
    "            clean_words.append(origin_word)\n",
    "            \n",
    "    temp.append((y, clean_words))                         # W2V不能去除重複字，不然算相似詞會有問題\n",
    "    temp1.append((y, list(set(clean_words))))             # 計算權重時去除重複字\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1ebfbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(temp, columns=[\"y\", \"clean_words\"]).to_pickle(\"clean_{}.pk\".format(target))\n",
    "pd.DataFrame(temp1, columns=[\"y\", \"clean_words\"]).to_pickle(\"clean_{}_VAL.pk\".format(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20b13959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd87a9e3",
   "metadata": {},
   "source": [
    "# validation也要整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "108a3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Validation\"\n",
    "\n",
    "# 訓練資料檔案名稱\n",
    "listdirs = os.listdir(target)\n",
    "\n",
    "# [(text,y), (text,y), .....]\n",
    "data = []\n",
    "for d in listdirs:\n",
    "    with open(\"{}/{}\".format(target,d), \"r\") as f:\n",
    "        text = f.read()\n",
    "    data.append((text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67074ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "temp1 = []\n",
    "for d in data:\n",
    "    text = d\n",
    "    \n",
    "    # 移除標點符號\n",
    "    text = remove_punctuation(text)\n",
    "\n",
    "    # 斷字\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    \n",
    "    # 詞性\n",
    "    words_tags = pos_tag(words)     # 獲取單詞詞性\n",
    "    \n",
    "    \n",
    "    # 去除停用字 且 字長度>2\n",
    "    nltk_stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    wnl = WordNetLemmatizer()\n",
    "    clean_words = []\n",
    "    for word_tag in words_tags:\n",
    "        wordnet_pos = get_wordnet_pos(word_tag[1]) or wordnet.NOUN\n",
    "        origin_word = wnl.lemmatize(word_tag[0], pos=wordnet_pos)    # 詞性還原\n",
    "#         print(word_tag[0], origin_word)\n",
    "        \n",
    "        if origin_word not in nltk_stopwords and len(origin_word) > 2:\n",
    "            clean_words.append(origin_word)\n",
    "            \n",
    "    temp.append((None,clean_words))                    # W2V不能去除重複字，不然算相似詞會有問題，因為還未有預測結果我先填None\n",
    "    temp1.append((list(set(clean_words))))             # 計算權重時去除重複字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e91e82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>[myocardial, infarction, sign, dis, admission,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>[tmc, coronary, artery, disease, sign, dis, ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>[rhc, asymptomatic, pyuria, dis, admission, da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>[congestive, heart, failure, sign, dis, admiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>[cuc, discharge, summary, sign, dis, admission...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>[tghhc, coronary, artery, disease, sign, dis, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>[smh, chf, exacerbation, dis, admission, date,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>[ush, congestive, heart, failure, dis, admissi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>[gcwgh, discharge, summary, sign, dis, admissi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>[cgh, discharge, summary, unsigned, dis, admis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>None</td>\n",
       "      <td>[gscho, discharge, summary, sign, dis, admissi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>[diverticular, abscess, sign, dis, admission, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>None</td>\n",
       "      <td>[rule, myocardial, infarction, sign, dis, admi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>None</td>\n",
       "      <td>[cmc, ischemic, colitis, sign, dis, admission,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>None</td>\n",
       "      <td>[cmc, chf, hemoptysis, dis, admission, date, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>None</td>\n",
       "      <td>[cmc, elevation, stent, thrombosis, dis, admis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>None</td>\n",
       "      <td>[vuh, cellulitis, sign, dis, admission, date, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>None</td>\n",
       "      <td>[omh, discharge, summary, unsigned, dis, admis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>None</td>\n",
       "      <td>[sumco, discharge, summary, unsigned, dis, adm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>None</td>\n",
       "      <td>[npmmh, discharge, summary, sign, dis, admissi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>None</td>\n",
       "      <td>[ccch, discharge, summary, sign, dis, admissio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>None</td>\n",
       "      <td>[ehmc, discharge, summary, unsigned, dis, admi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>None</td>\n",
       "      <td>[mlvmc, discharge, summary, sign, dis, admissi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>None</td>\n",
       "      <td>[post, low, extremity, edema, unsigned, dis, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>None</td>\n",
       "      <td>[alh, discharge, summary, sign, dis, admission...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>None</td>\n",
       "      <td>[gemc, diff, colitis, unsigned, dis, admission...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>None</td>\n",
       "      <td>[lhc, discharge, summary, sign, dis, admission...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>None</td>\n",
       "      <td>[tpah, congestive, heart, failure, sign, dis, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>None</td>\n",
       "      <td>[amc, three, vessell, disease, sign, dis, admi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>None</td>\n",
       "      <td>[ssmc, discharge, summary, unsigned, dis, admi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>None</td>\n",
       "      <td>[lhc, pulmonary, embolism, sign, dis, admissio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>None</td>\n",
       "      <td>[discharge, summary, sign, dis, admission, dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>None</td>\n",
       "      <td>[coronary, artery, disease, sign, dis, admissi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>None</td>\n",
       "      <td>[discharge, summary, sign, dis, admission, dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>None</td>\n",
       "      <td>[rgh, bone, cancer, unsigned, dis, admission, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>None</td>\n",
       "      <td>[discharge, summary, unsigned, dis, admission,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>None</td>\n",
       "      <td>[aortic, stenosis, sign, dis, admission, date,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>None</td>\n",
       "      <td>[pmc, congestive, heart, failure, dis, admissi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>None</td>\n",
       "      <td>[pemh, discharge, summary, sign, dis, admissio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>None</td>\n",
       "      <td>[sah, myocardial, infarction, sign, dis, admis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>None</td>\n",
       "      <td>[pneumonia, sign, dis, admission, date, report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>None</td>\n",
       "      <td>[ihc, atrial, fibrillation, sign, dis, admissi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>None</td>\n",
       "      <td>[ssmc, nstemi, chf, dis, admission, date, repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>None</td>\n",
       "      <td>[rhamc, discharge, summary, sign, dis, admissi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>None</td>\n",
       "      <td>[ommc, coronary, artery, disease, sign, dis, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>None</td>\n",
       "      <td>[wmc, acute, myocardial, infarction, sign, dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>None</td>\n",
       "      <td>[gmh, discharge, summary, sign, dis, admission...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>None</td>\n",
       "      <td>[discharge, summary, sign, dis, admission, dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>None</td>\n",
       "      <td>[rhmc, leave, leg, pain, hypocalcemia, dis, ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>None</td>\n",
       "      <td>[macmc, dyspnea, dis, admission, date, report,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                                                  1\n",
       "0   None  [myocardial, infarction, sign, dis, admission,...\n",
       "1   None  [tmc, coronary, artery, disease, sign, dis, ad...\n",
       "2   None  [rhc, asymptomatic, pyuria, dis, admission, da...\n",
       "3   None  [congestive, heart, failure, sign, dis, admiss...\n",
       "4   None  [cuc, discharge, summary, sign, dis, admission...\n",
       "5   None  [tghhc, coronary, artery, disease, sign, dis, ...\n",
       "6   None  [smh, chf, exacerbation, dis, admission, date,...\n",
       "7   None  [ush, congestive, heart, failure, dis, admissi...\n",
       "8   None  [gcwgh, discharge, summary, sign, dis, admissi...\n",
       "9   None  [cgh, discharge, summary, unsigned, dis, admis...\n",
       "10  None  [gscho, discharge, summary, sign, dis, admissi...\n",
       "11  None  [diverticular, abscess, sign, dis, admission, ...\n",
       "12  None  [rule, myocardial, infarction, sign, dis, admi...\n",
       "13  None  [cmc, ischemic, colitis, sign, dis, admission,...\n",
       "14  None  [cmc, chf, hemoptysis, dis, admission, date, r...\n",
       "15  None  [cmc, elevation, stent, thrombosis, dis, admis...\n",
       "16  None  [vuh, cellulitis, sign, dis, admission, date, ...\n",
       "17  None  [omh, discharge, summary, unsigned, dis, admis...\n",
       "18  None  [sumco, discharge, summary, unsigned, dis, adm...\n",
       "19  None  [npmmh, discharge, summary, sign, dis, admissi...\n",
       "20  None  [ccch, discharge, summary, sign, dis, admissio...\n",
       "21  None  [ehmc, discharge, summary, unsigned, dis, admi...\n",
       "22  None  [mlvmc, discharge, summary, sign, dis, admissi...\n",
       "23  None  [post, low, extremity, edema, unsigned, dis, a...\n",
       "24  None  [alh, discharge, summary, sign, dis, admission...\n",
       "25  None  [gemc, diff, colitis, unsigned, dis, admission...\n",
       "26  None  [lhc, discharge, summary, sign, dis, admission...\n",
       "27  None  [tpah, congestive, heart, failure, sign, dis, ...\n",
       "28  None  [amc, three, vessell, disease, sign, dis, admi...\n",
       "29  None  [ssmc, discharge, summary, unsigned, dis, admi...\n",
       "30  None  [lhc, pulmonary, embolism, sign, dis, admissio...\n",
       "31  None  [discharge, summary, sign, dis, admission, dat...\n",
       "32  None  [coronary, artery, disease, sign, dis, admissi...\n",
       "33  None  [discharge, summary, sign, dis, admission, dat...\n",
       "34  None  [rgh, bone, cancer, unsigned, dis, admission, ...\n",
       "35  None  [discharge, summary, unsigned, dis, admission,...\n",
       "36  None  [aortic, stenosis, sign, dis, admission, date,...\n",
       "37  None  [pmc, congestive, heart, failure, dis, admissi...\n",
       "38  None  [pemh, discharge, summary, sign, dis, admissio...\n",
       "39  None  [sah, myocardial, infarction, sign, dis, admis...\n",
       "40  None  [pneumonia, sign, dis, admission, date, report...\n",
       "41  None  [ihc, atrial, fibrillation, sign, dis, admissi...\n",
       "42  None  [ssmc, nstemi, chf, dis, admission, date, repo...\n",
       "43  None  [rhamc, discharge, summary, sign, dis, admissi...\n",
       "44  None  [ommc, coronary, artery, disease, sign, dis, a...\n",
       "45  None  [wmc, acute, myocardial, infarction, sign, dis...\n",
       "46  None  [gmh, discharge, summary, sign, dis, admission...\n",
       "47  None  [discharge, summary, sign, dis, admission, dat...\n",
       "48  None  [rhmc, leave, leg, pain, hypocalcemia, dis, ad...\n",
       "49  None  [macmc, dyspnea, dis, admission, date, report,..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb204393",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "1 columns passed, passed data had 1162 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;31m# caller's responsibility to check for this...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m             raise AssertionError(\n\u001b[0m\u001b[0;32m    693\u001b[0m                 \u001b[1;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 1 columns passed, passed data had 1162 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e548559fb014>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"clean_words\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"clean_{}.pk\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"clean_words\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"clean_{}_VAL.pk\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    568\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m                     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# columns if columns is not None else []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         return _list_of_dict_to_arrays(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 1 columns passed, passed data had 1162 columns"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(temp, columns=[\"clean_words\"]).to_pickle(\"clean_{}.pk\".format(target))\n",
    "pd.DataFrame(temp1, columns=[\"clean_words\"]).to_pickle(\"clean_{}_VAL.pk\".format(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea150f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
